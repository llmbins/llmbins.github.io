---
description: |
  NVIDIA Garak is a powerful command-line tool for probing vulnerabilities in Large Language Models (LLMs). It supports a wide range of models and environments, enabling you to test for issues like prompt injection, data leakage, hallucinations, toxicity, and jailbreaks. 

  Garak simplifies red-teaming for LLMs, offering detailed insights into model behavior through various probes and detectors. It supports models from Hugging Face, OpenAI, Replicate, Cohere, and many others.

  **Command Reference**:
    - Install: `python -m pip install -U garak`
    - Example Usage: `python3 -m garak --model_type huggingface --model_name bert-base-uncased`

command: |
  # Install Garak
  python -m pip install -U garak
  
  # Example: Test Hugging Face GPT2 for vulnerabilities
  python3 -m garak --model_type huggingface --model_name gpt2 --probes dan.Dan_11_0
items:
  - Model_Type
  - Model_Name
  - API_Key
services:
  - HuggingFace
  - OpenAI
  - Replicate
  - Cohere
  - NVIDIA
attack_types:
  - Vulnerability_Assessment
  - Prompt_Injection
  - Hallucination_Detection
  - Data_Leakage
  - Toxicity
OS:
  - Linux
  - MacOS
  - Docker
references:
  - https://github.com/NVIDIA/garak
  - https://garak.ai/
  - https://reference.garak.ai/en/latest/
---
